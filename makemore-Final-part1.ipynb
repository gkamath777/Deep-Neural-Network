{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16db6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c26380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17d1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "#s = tuple(enumerate(chars))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d814c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of examples 228146\n"
     ]
    }
   ],
   "source": [
    "#create the Dataset\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w)+ ['.']\n",
    "    for ch1, ch2 in zip (chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('num of examples', num)\n",
    "\n",
    "#randoly intialize 27 neurons weights. Each neuron recieves 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "w = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc5bd556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4814438819885254\n",
      "2.4604711532592773\n",
      "2.4576287269592285\n",
      "2.4575355052948\n",
      "2.4575068950653076\n",
      "2.4574897289276123\n",
      "2.4574766159057617\n",
      "2.4574649333953857\n",
      "2.4574546813964844\n",
      "2.457444429397583\n",
      "2.457435131072998\n",
      "2.457425832748413\n",
      "2.4574167728424072\n",
      "2.4574077129364014\n",
      "2.4573988914489746\n",
      "2.457390308380127\n",
      "2.4573814868927\n",
      "2.4573729038238525\n",
      "2.457364082336426\n",
      "2.4573557376861572\n",
      "2.4573473930358887\n",
      "2.457338809967041\n",
      "2.4573304653167725\n",
      "2.457322359085083\n",
      "2.4573137760162354\n",
      "2.4573051929473877\n",
      "2.4572973251342773\n",
      "2.457289218902588\n",
      "2.4572811126708984\n",
      "2.457273006439209\n",
      "2.4572653770446777\n",
      "2.457257032394409\n",
      "2.457249164581299\n",
      "2.4572412967681885\n",
      "2.457233190536499\n",
      "2.4572253227233887\n",
      "2.4572176933288574\n",
      "2.457210063934326\n",
      "2.457202196121216\n",
      "2.4571945667266846\n",
      "2.4571869373321533\n",
      "2.457179307937622\n",
      "2.457171678543091\n",
      "2.4571640491485596\n",
      "2.4571566581726074\n",
      "2.4571492671966553\n",
      "2.457141637802124\n",
      "2.457134246826172\n",
      "2.4571268558502197\n",
      "2.4571194648742676\n",
      "2.4571120738983154\n",
      "2.4571046829223633\n",
      "2.4570975303649902\n",
      "2.4570906162261963\n",
      "2.4570834636688232\n",
      "2.45707631111145\n",
      "2.457069158554077\n",
      "2.457062005996704\n",
      "2.457054853439331\n",
      "2.457047700881958\n",
      "2.457040548324585\n",
      "2.45703387260437\n",
      "2.457026720046997\n",
      "2.4570200443267822\n",
      "2.4570133686065674\n",
      "2.4570062160491943\n",
      "2.4569995403289795\n",
      "2.4569923877716064\n",
      "2.4569859504699707\n",
      "2.456979274749756\n",
      "2.456972360610962\n",
      "2.456965684890747\n",
      "2.4569590091705322\n",
      "2.4569525718688965\n",
      "2.4569458961486816\n",
      "2.456939220428467\n",
      "2.456932783126831\n",
      "2.4569263458251953\n",
      "2.4569201469421387\n",
      "2.4569132328033447\n",
      "2.456907033920288\n",
      "2.4569005966186523\n",
      "2.4568943977355957\n",
      "2.456887722015381\n",
      "2.4568817615509033\n",
      "2.4568750858306885\n",
      "2.456869125366211\n",
      "2.456862688064575\n",
      "2.4568564891815186\n",
      "2.456850290298462\n",
      "2.4568443298339844\n",
      "2.4568381309509277\n",
      "2.456831932067871\n",
      "2.4568259716033936\n",
      "2.456819772720337\n",
      "2.4568138122558594\n",
      "2.456807851791382\n",
      "2.4568018913269043\n",
      "2.4567956924438477\n",
      "2.456789970397949\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "for k in range(100):\n",
    "    # Forward pass\n",
    "\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = xenc @ w\n",
    "    counts = logits.exp()\n",
    "    probs = counts/ counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(num), ys].log().mean()\n",
    "    \n",
    "    print(loss.item())\n",
    "    \n",
    "    # Backward pass\n",
    "    w.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    w.data += -50 * w.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
